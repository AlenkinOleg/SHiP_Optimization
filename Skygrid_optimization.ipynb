{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "warning in stationary: failed to import cython module: falling back to numpy\n"
     ]
    }
   ],
   "source": [
    "import GPyOpt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KINIT_USERNAME = 'login'\n",
    "KINIT_PASSWD = 'passwd'\n",
    "N_EVENTS = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_dist = 3.6\n",
    "\n",
    "space = [{'name': 'pitch', 'type': 'continuous', 'domain': (min_dist, min_dist)},\\\n",
    "         {'name': 'yoffset_layer', 'type': 'continuous', 'domain': (min_dist/2, min_dist)},\\\n",
    "         {'name': 'yoffset_plane', 'type': 'continuous', 'domain': (min_dist*0.25, min_dist*1.25)},\\\n",
    "         {'name': 'zshift_layer', 'type': 'continuous', 'domain': (1.6, 2.6)},\\\n",
    "         {'name': 'zshift_plane', 'type': 'continuous', 'domain': (3.8, 6.8)},\\\n",
    "         {'name': 'zshift_view', 'type': 'continuous', 'domain': (10, 10)},\\\n",
    "         {'name': 'alpha', 'type': 'discrete', 'domain': (5, 5)}]\n",
    "\n",
    "constraints = [{'name': 'constr_1', 'constrain': '-(x[:,0]-x[:,1])**2-x[:,3]**2+2**2'},\\\n",
    "               {'name': 'constr_2', 'constrain': '-(x[:,1]-x[:,2])**2-(x[:,3]-x[:,4])**2+2**2'},\\\n",
    "               {'name': 'constr_3', 'constrain': 'x[:,3]+x[:,4]+2-x[:,5]'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feasible_region = GPyOpt.Design_space(space=space, constraints=constraints)\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import skygrid client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import json\n",
    "\n",
    "from disneylandClient import (\n",
    "    new_client,\n",
    "    Job,\n",
    "    RequestWithId,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "STATUS_IN_PROCESS = set([\n",
    "    Job.PENDING,\n",
    "    Job.PULLED,\n",
    "    Job.RUNNING,\n",
    "])\n",
    "STATUS_FINAL = set([\n",
    "    Job.COMPLETED,\n",
    "    Job.FAILED,\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def return_descriptor(point):\n",
    "    \n",
    "    pitch, yoffset_layer, yoffset_plane, zshift_layer, zshift_plane, zshift_view, alpha = point\n",
    "    \n",
    "    logining = \"sh -lc 'echo \"+KINIT_PASSWD+\" | kinit \"+KINIT_USERNAME+\"; \"\n",
    "    sourcing = \"source /opt/FairShipRun/config.sh; \"\n",
    "    simulation = \"python $SHIPOPT/code/objective.py --pitch \"+str(pitch)+\" --yoffset_layer \"+str(yoffset_layer)+\\\n",
    "              \" --yoffset_plane \"+str(yoffset_plane)+\" --zshift_layer \"+str(zshift_layer)+\" --zshift_plane \"+\\\n",
    "              str(zshift_plane)+\" --zshift_view \"+str(zshift_view)+\" --alpha \"+str(int(alpha))+\\\n",
    "              \" --nEvents \"+str(N_EVENTS)+\" --output /output/output.txt'\"\n",
    "    cmd = logining+sourcing+simulation\n",
    "\n",
    "    descriptor = {\n",
    "        \"descriptor\": {\n",
    "            \"input\": [],\n",
    "\n",
    "            \"container\": {\n",
    "                \"workdir\": \"\",\n",
    "                \"name\": \"oleg94/worker\",\n",
    "                \"cpu_needed\": 1,\n",
    "                \"max_memoryMB\": 4096,\n",
    "                \"min_memoryMB\": 1024,\n",
    "                \"cmd\": cmd,\n",
    "            },\n",
    "\n",
    "            \"required_outputs\": {\n",
    "                \"output_uri\": \"none:\",\n",
    "                \"file_contents\": [\n",
    "                    {\"file\": \"output.txt\", \"to_variable\": \"out\"}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return descriptor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initial design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_estimators = 80\n",
    "n_initial_design = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_design = GPyOpt.experiment_design.initial_design('random', feasible_region, n_initial_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "initial_objective = np.zeros(n_initial_design)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stub = new_client()\n",
    "jobs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 started.\n",
      "Finished jobs: 0 Running jobs: 0 Pending jobs: 20\n",
      "Finished jobs: 0 Running jobs: 20 Pending jobs: 0\n"
     ]
    }
   ],
   "source": [
    "init_d_i = 0\n",
    "\n",
    "for epoch in range(n_initial_design // n_estimators):\n",
    "    \n",
    "    print(\"EPOCH #\"+str(epoch)+\" started.\")\n",
    "    \n",
    "    epoch_jobs = [0] * n_estimators\n",
    "    \n",
    "    for k in range(n_estimators):\n",
    "        descriptor = return_descriptor(initial_design[init_d_i])\n",
    "        init_d_i += 1\n",
    "        epoch_jobs[k] = Job(input=json.dumps(descriptor), kind=\"docker\")\n",
    "        epoch_jobs[k] = stub.CreateJob(epoch_jobs[k])\n",
    "    \n",
    "    prev_number_of_finished_jobs = 0\n",
    "    prev_number_of_running_jobs = 0\n",
    "    prev_number_of_pending_jobs = 0\n",
    "    \n",
    "    while True:\n",
    "        for k in range(n_estimators):\n",
    "            epoch_jobs[k] = stub.GetJob(RequestWithId(id=epoch_jobs[k].id))\n",
    "        \n",
    "        number_of_finished_jobs = 0\n",
    "        number_of_running_jobs = 0\n",
    "        number_of_pending_jobs = 0\n",
    "        for k in range(n_estimators):\n",
    "            if epoch_jobs[k].status in STATUS_FINAL:\n",
    "                number_of_finished_jobs += 1\n",
    "            if epoch_jobs[k].status == Job.PENDING:\n",
    "                number_of_pending_jobs += 1\n",
    "            if epoch_jobs[k].status == Job.RUNNING:\n",
    "                number_of_running_jobs += 1\n",
    "                \n",
    "        if (number_of_finished_jobs != prev_number_of_finished_jobs) or (prev_number_of_running_jobs != number_of_running_jobs) or (prev_number_of_pending_jobs != number_of_pending_jobs):\n",
    "            print(\"Finished jobs: \"+str(number_of_finished_jobs)+\\\n",
    "                  \" Running jobs: \"+str(number_of_running_jobs)+\\\n",
    "                  \" Pending jobs: \"+str(number_of_pending_jobs))\n",
    "            prev_number_of_finished_jobs = number_of_finished_jobs\n",
    "            prev_number_of_running_jobs = number_of_running_jobs\n",
    "            prev_number_of_pending_jobs = number_of_pending_jobs\n",
    "            \n",
    "        if number_of_finished_jobs == n_estimators:\n",
    "            break\n",
    "        time.sleep(120)\n",
    "    \n",
    "    jobs += epoch_jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_init_design = pd.DataFrame(initial_design, columns=['pitch', 'yoffset_layer', 'yoffset_plane', 'zshift_layer', 'zshift_plane', 'zshift_view', 'alpha'])\n",
    "df_init_design['objective'] = [float(re.sub('[\\[\\]\"variable:out=]', '', job.output)) if re.sub('[\\[\\]\"variable:out=]', '', job.output) else np.nan for job in jobs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_init_design.to_csv('observations/observations.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main part of optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_init_design = pd.read_csv('observations/observations.csv')\n",
    "n_estimators = 10\n",
    "n_epochs = 100\n",
    "stub = new_client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH #0 started.\n",
      "Finished jobs: 0 Running jobs: 0 Pending jobs: 1\n",
      "Finished jobs: 1 Running jobs: 0 Pending jobs: 0\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_epochs):\n",
    "    \n",
    "        print(\"EPOCH #\"+str(epoch)+\" started.\")\n",
    "    \n",
    "        epoch_jobs = [0] * n_estimators\n",
    "        \n",
    "        pending_X = []\n",
    "\n",
    "        for k in range(n_estimators):\n",
    "            \n",
    "            step_X = df_init_design[df_init_design.columns[:-1]].values\n",
    "            #because we want to maximize\n",
    "            step_Y = -df_init_design[df_init_design.columns[-1:]].values\n",
    "            ignored_X = step_X[np.isnan(step_Y.ravel())]\n",
    "            step_X = step_X[~np.isnan(step_Y.ravel())]\n",
    "            step_Y = step_Y[~np.isnan(step_Y.ravel())]\n",
    "            bo = GPyOpt.methods.BayesianOptimization(f=None, domain=space, constraints=constraints, X=step_X,\\\n",
    "                                                     Y=step_Y, de_duplication=True, initial_design_numdata=200)\n",
    "            new_point = bo.suggest_next_locations(pending_X=np.array(pending_X), ignored_X=ignored_X)[0]\n",
    "\n",
    "            descriptor = return_descriptor(new_point)\n",
    "            epoch_jobs[k] = Job(input=json.dumps(descriptor), kind=\"docker\")\n",
    "            epoch_jobs[k] = stub.CreateJob(epoch_jobs[k])\n",
    "            \n",
    "            pending_X += [new_point]\n",
    "        \n",
    "        prev_number_of_finished_jobs = 0\n",
    "        prev_number_of_running_jobs = 0\n",
    "        prev_number_of_pending_jobs = 0\n",
    "\n",
    "        while True:\n",
    "            for k in range(n_estimators):\n",
    "                epoch_jobs[k] = stub.GetJob(RequestWithId(id=epoch_jobs[k].id))\n",
    "\n",
    "            number_of_finished_jobs = 0\n",
    "            number_of_running_jobs = 0\n",
    "            number_of_pending_jobs = 0\n",
    "            for k in range(n_estimators):\n",
    "                if epoch_jobs[k].status in STATUS_FINAL:\n",
    "                    number_of_finished_jobs += 1\n",
    "                if epoch_jobs[k].status == Job.PENDING:\n",
    "                    number_of_pending_jobs += 1\n",
    "                if epoch_jobs[k].status == Job.RUNNING:\n",
    "                    number_of_running_jobs += 1\n",
    "\n",
    "            if (number_of_finished_jobs != prev_number_of_finished_jobs) or (prev_number_of_running_jobs != number_of_running_jobs) or (prev_number_of_pending_jobs != number_of_pending_jobs):\n",
    "                print(\"Finished jobs: \"+str(number_of_finished_jobs)+\\\n",
    "                      \" Running jobs: \"+str(number_of_running_jobs)+\\\n",
    "                      \" Pending jobs: \"+str(number_of_pending_jobs))\n",
    "                prev_number_of_finished_jobs = number_of_finished_jobs\n",
    "                prev_number_of_running_jobs = number_of_running_jobs\n",
    "                prev_number_of_pending_jobs = number_of_pending_jobs\n",
    "\n",
    "            if number_of_finished_jobs == n_estimators:\n",
    "                break\n",
    "            time.sleep(120)\n",
    "            \n",
    "        for k, point in enumerate(pending_X):\n",
    "        \n",
    "            value = float(re.sub('[\\[\\]\"variable:out=]', '', epoch_jobs[k].output)) if re.sub('[\\[\\]\"variable:out=]', '', epoch_jobs[k].output) else np.nan\n",
    "        \n",
    "            df_init_design.loc[len(df_init_design)] = list(point)+[value]\n",
    "            df_init_design.to_csv('observations/observations.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
